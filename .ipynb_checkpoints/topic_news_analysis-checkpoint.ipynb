{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "np.random.seed(2018)\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_all= pd.read_csv(\"test_news_translated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (gensim.utils.simple_preprocess(str(sentence),deacc=True))\n",
    "        \n",
    "stopwords_verbs = ['say',\"ecuadorian\",\"jair\",\"mauricio\",\"argentinian\",\"bueno\",\"summari\",\"paraguayan\",\"uruguayan\",\"franci\",\"lionel\",\"francisco\",\"chang\",\"hondura\",\"honduran\",\"julian\",\"nicaraguan\",\"lenin\",\"best\",\"confirm\",\"tell\",\"stori\",\"month\",\"year\",\"president\",\"colombian\",\"ecuador\",\"presid\",'lenin','get', 'go','know', 'may', 'need', 'like', 'make', 'see', 'want', 'come', 'take', 'use', 'would', 'can']\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if (len(word)>3) and (word not in stopwords_verbs) ] for doc in texts]\n",
    "\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def crearMatriz(dic,doc,corpus):\n",
    "    matriz= np.zeros((len(doc),len(dic)))\n",
    "    for doc in range(len(doc)):\n",
    "        for word in range(len(corpus[doc])):\n",
    "            matriz[doc][(corpus[doc][word][0])]+= corpus[doc][word][1]  \n",
    "    return pd.DataFrame(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPIC MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(data, filter_extreme=True,below=5, above=0.5):\n",
    "    id2word = gensim.corpora.Dictionary(data_words_nostops)# sin filtroooooo\n",
    "    if filter_extreme:\n",
    "        id2word.filter_extremes(no_below= below, no_above= above, keep_n=100000)\n",
    "        return id2word\n",
    "    return id2word\n",
    "        \n",
    "    \n",
    "def corpus(data):\n",
    "    corpus = [id2word.doc2bow(data) for text in data] # Bag of words\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "def top_of_words(data,id2word,corpus,save=True):\n",
    "        bow=crearMatriz(dic=id2word,doc= data_words_nostops , corpus=corpus)\n",
    "        lista_palabras=[]\n",
    "        for i in range(len(id2word)):\n",
    "            lista_palabras.append(id2word[i])\n",
    "        bow.columns = lista_palabras\n",
    "        top_palabras= bow.sum(axis=0).sort_values(ascending=False) \n",
    "        words=pd.DataFrame(top_palabras.head(10)).reset_index()\n",
    "        words.columns= [\"words\", \"count\"]\n",
    "        words[\"country\"]=pd.DataFrame([country]*10)\n",
    "        words[\"ano\"]=pd.DataFrame([ano]*10)\n",
    "        listaTops.append(words)\n",
    "        if save:\n",
    "            words.to_csv(country+\"_\"+str(ano)+\".csv\")\n",
    "            \n",
    "            \n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    \n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num)+1, round(prop_topic,4), topic_keywords, ano]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords', \"year\"]\n",
    "    sent_topics_df[\"country\"]=pd.DataFrame([country]*len(noticias))\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)                \n",
    "\n",
    "\n",
    "\n",
    "def topic_modeling(news_all, country, year):  \n",
    "        news= news_all[(news_all[\"country\"]==country)&(news_all[\"year\"]==ano)]\n",
    "        #data= news[\"tokens-title-stopwords-stemming\"].values\n",
    "        doc_words= list(sent_to_words(news[\"tokens-title-stopwords-stemming\"].values))\n",
    "        data_words_nostops= remove_stopwords(doc_words)\n",
    "        id2word= dictionary(data_words_nostops, filter_extreme=True,below=5, above=0.5)\n",
    "        corpus= corpus(data_words_nostops)\n",
    "        #model \n",
    "        tfidf= models.TfidfModel(corpus)\n",
    "        corpus_tfidf= tfidf[corpus]\n",
    "        lda_model_TFIDF = gensim.models.LdaMulticore(corpus=corpus_tfidf,id2word=id2word,num_topics=5,random_state=100,chunksize=50,passes=10,per_word_topics=True)\n",
    "        return lda_model_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[]\n",
    "listaTops=[]\n",
    "for pais in paises:\n",
    "    for year in years:\n",
    "        topic_modeling(news_all, country, year)\n",
    "        lista_news= [new for new in news.title]\n",
    "        df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model_TFIDF, corpus=corpus_tfidf,texts=lista_news)\n",
    "        all_data.append(df_topic_sents_keywords)\n",
    "result = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>final, abort, river, boca, iceland, return, do...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>argentina</td>\n",
       "      <td>Argentina: el Senado rechaza la nueva ley de a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>messi, footbal, match, russia, beat, peso, sel...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>argentina</td>\n",
       "      <td>Rusia 2018: Argentina clasifica a octavos de f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>nigeria, franc, spain, face, market, emerg, ge...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>argentina</td>\n",
       "      <td>Eliminada Argentina de Rusia 2018 al caer 4-3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4514</td>\n",
       "      <td>macri, play, croatia, coach, goal, talk, suppo...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>argentina</td>\n",
       "      <td>Rusia 2018: Croacia golea a una decepcionante ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>final, abort, river, boca, iceland, return, do...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>argentina</td>\n",
       "      <td>ARA San Juan: por qué es difícil rescatar el s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>sanction, kill, border, offici, drone, worst, ...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>UN 'running out of cash' and facing urgent cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>nicola, start, earthquak, accus, russia, jose,...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>Inside the 14 December edition of the Guardian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>crisi, currenc, price, product, spain, govern,...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>Oil prices could spiral higher in the coming m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>vinotinto, photo, hunger, hyperinfl, flee, mig...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>World Press Photo Contest 2018 – the nominees ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>vinotinto, photo, hunger, hyperinfl, flee, mig...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>Brazil fails to replace thousands of doctors w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dominant_Topic  Perc_Contribution  \\\n",
       "0               5.0             0.6651   \n",
       "1               3.0             0.3642   \n",
       "2               1.0             0.6942   \n",
       "3               2.0             0.4514   \n",
       "4               5.0             0.4946   \n",
       "..              ...                ...   \n",
       "604             5.0             0.6000   \n",
       "605             1.0             0.2000   \n",
       "606             3.0             0.6000   \n",
       "607             2.0             0.6000   \n",
       "608             2.0             0.6000   \n",
       "\n",
       "                                        Topic_Keywords    year    country  \\\n",
       "0    final, abort, river, boca, iceland, return, do...  2018.0  argentina   \n",
       "1    messi, footbal, match, russia, beat, peso, sel...  2018.0  argentina   \n",
       "2    nigeria, franc, spain, face, market, emerg, ge...  2018.0  argentina   \n",
       "3    macri, play, croatia, coach, goal, talk, suppo...  2018.0  argentina   \n",
       "4    final, abort, river, boca, iceland, return, do...  2018.0  argentina   \n",
       "..                                                 ...     ...        ...   \n",
       "604  sanction, kill, border, offici, drone, worst, ...  2018.0  venezuela   \n",
       "605  nicola, start, earthquak, accus, russia, jose,...  2018.0  venezuela   \n",
       "606  crisi, currenc, price, product, spain, govern,...  2018.0  venezuela   \n",
       "607  vinotinto, photo, hunger, hyperinfl, flee, mig...  2018.0  venezuela   \n",
       "608  vinotinto, photo, hunger, hyperinfl, flee, mig...  2018.0  venezuela   \n",
       "\n",
       "                                                     0  \n",
       "0    Argentina: el Senado rechaza la nueva ley de a...  \n",
       "1    Rusia 2018: Argentina clasifica a octavos de f...  \n",
       "2    Eliminada Argentina de Rusia 2018 al caer 4-3 ...  \n",
       "3    Rusia 2018: Croacia golea a una decepcionante ...  \n",
       "4    ARA San Juan: por qué es difícil rescatar el s...  \n",
       "..                                                 ...  \n",
       "604  UN 'running out of cash' and facing urgent cut...  \n",
       "605  Inside the 14 December edition of the Guardian...  \n",
       "606  Oil prices could spiral higher in the coming m...  \n",
       "607  World Press Photo Contest 2018 – the nominees ...  \n",
       "608  Brazil fails to replace thousands of doctors w...  \n",
       "\n",
       "[9204 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words.to_excel('topWords_todosPaises2.xlsx')\n",
    "result.to_excel(\"topicos_todosPaisesFILTRO.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
